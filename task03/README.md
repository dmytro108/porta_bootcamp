# Task 03: MySQL Cleanup Procedure Benchmark

## Overview

This project implements and benchmarks four different methods for cleaning up old data from large MySQL tables (millions of records). The goal is to determine the fastest and most efficient approach for production environments.

## Context

- **Environment**: MySQL 8 with master-slave replication
- **Requirement**: Remove records older than 10 days from tables with ~1M records per day
- **Challenge**: Minimize impact on application performance and replication lag

## Cleanup Methods

### 1. DROP PARTITION - The Speed Champion â­

**Best method when partitioning is available**

Drops entire partitions containing old data in a single DDL operation.

**SQL**: `ALTER TABLE cleanup_partitioned DROP PARTITION p20251101, p20251102;`

**Characteristics**:
- âš¡ Fastest (4,000-10,000+ rows/sec, often millions)
- âœ… Selective (keeps recent data)
- ğŸ“Š Minimal replication lag (<1 second)
- ğŸ’¾ Full space recovery
- ğŸ§¹ Zero fragmentation
- â±ï¸ Brief metadata lock only

**Requirements**:
- Table must be partitioned by date/time
- Partition boundaries must align with retention policy

**When to use**:
- Production tables with date-based partitioning
- Regular cleanup schedule (daily/weekly)
- Speed is critical
- **This is the recommended method when possible**

**Usage**:
```bash
./run-in-container.sh db-cleanup.sh --method partition_drop
./run-in-container.sh db-cleanup.sh --method partition_drop --retention-days 7
```

---

### 2. TRUNCATE TABLE - The Quick Reset

âš ï¸ **WARNING: Removes ALL data, not selective (does NOT meet 10-day retention requirement)**

Truncates entire table, recreating it empty.

**SQL**: `TRUNCATE TABLE cleanup_truncate;`

**Characteristics**:
- âš¡ Very fast (50,000+ rows/sec)
- âŒ **Removes ALL data** (not selective - doesn't keep recent 10 days)
- ğŸ“Š Minimal replication lag (<2 seconds)
- ğŸ’¾ Full space recovery
- ğŸ§¹ Zero fragmentation
- â±ï¸ Brief table lock

**When to use**:
- Batch processing, temporary tables, staging tables
- Entire table can be cleared
- **NOT suitable for production tables with retention requirements**

**Usage**:
```bash
./run-in-container.sh db-cleanup.sh --method truncate
```

---

### 3. Copy-to-New-Table - The Defragmenter

Creates new table, copies recent data, swaps tables, drops old.

**SQL** (4-step process):
```sql
CREATE TABLE cleanup_copy_new LIKE cleanup_copy;
INSERT INTO cleanup_copy_new SELECT * WHERE ts >= NOW() - INTERVAL 10 DAY;
RENAME TABLE cleanup_copy TO cleanup_copy_old, cleanup_copy_new TO cleanup_copy;
DROP TABLE cleanup_copy_old;
```

**Characteristics**:
- ğŸ¢ Moderate speed (1,000-3,000 rows/sec)
- âœ… Selective (keeps recent data)
- ğŸ“Š High replication lag (10-60 seconds)
- ğŸ’¾ Full space recovery
- ğŸ§¹ Zero fragmentation
- âš ï¸ Brief table lock during RENAME
- âš ï¸ **Data written during execution is LOST**
- ğŸ’½ Requires 2x table space temporarily

**When to use**:
- Scheduled maintenance windows
- Tables without partitioning
- Fragmentation is a problem
- Acceptable brief downtime during RENAME

**Usage**:
```bash
./run-in-container.sh db-cleanup.sh --method copy
./run-in-container.sh db-cleanup.sh --method copy --retention-days 7
```

**Critical Warning**: Data written between CREATE and RENAME is permanently lost. Run during low-traffic periods or read-only mode.

---

### 4. Batch DELETE - The 24/7 Option

Deletes data in small batches in a loop.

**SQL** (repeated until no rows match):
```sql
DELETE FROM cleanup_batch 
WHERE ts < NOW() - INTERVAL 10 DAY 
ORDER BY ts 
LIMIT 5000;
```

**Characteristics**:
- ğŸŒ Slowest (500-2,000 rows/sec)
- âœ… Selective (keeps recent data)
- âœ… Table stays online (no locks)
- ğŸ“Š Medium-high replication lag (5-60 seconds)
- âŒ **No space freed** (requires OPTIMIZE TABLE)
- âŒ High fragmentation (20-50%)
- ğŸ“‰ Performance degrades over time

**Per-Batch Metrics**: Tracks throughput degradation across batches

**When to use**:
- Must keep table online 24/7
- Cannot use partitioning
- Acceptable performance degradation
- Can schedule OPTIMIZE TABLE later

**Usage**:
```bash
./run-in-container.sh db-cleanup.sh --method batch_delete
./run-in-container.sh db-cleanup.sh --method batch_delete --batch-size 10000
./run-in-container.sh db-cleanup.sh --method batch_delete --batch-size 5000 --batch-delay 0.2
```

**Post-Cleanup**:
```sql
-- Check fragmentation
SELECT TABLE_NAME, DATA_FREE, DATA_LENGTH, INDEX_LENGTH,
       ROUND(DATA_FREE / (DATA_LENGTH + INDEX_LENGTH) * 100, 2) AS fragmentation_pct
FROM information_schema.TABLES
WHERE TABLE_NAME = 'cleanup_batch';

-- Reclaim space (if fragmentation > 20%)
OPTIMIZE TABLE cleanup_bench.cleanup_batch;
```

---

## Method Comparison

| Method         | Selective? | Speed     | Repl Lag | Space Freed | Fragmentation | Table Online? | Partitioning Required? |
| -------------- | ---------- | --------- | -------- | ----------- | ------------- | ------------- | ---------------------- |
| DROP PARTITION | âœ… Yes      | Fastest   | Minimal  | 100%        | 0%            | Brief lock    | âœ… Yes                  |
| TRUNCATE       | âŒ **NO**   | Very Fast | Minimal  | 100%        | 0%            | Brief lock    | No                     |
| Copy           | âœ… Yes      | Moderate  | High     | 100%        | 0%            | Brief RENAME  | No                     |
| Batch DELETE   | âœ… Yes      | Slow      | Medium   | **0%***     | 20-50%        | âœ… Yes         | No                     |

*Requires OPTIMIZE TABLE to reclaim space

## Decision Tree

```
Need to cleanup old data (keep recent 10 days)?
â”‚
â”œâ”€ Is table partitioned by date?
â”‚  â”œâ”€ YES â†’ Use DROP PARTITION â­ (best - fast & selective)
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Can you delete ALL data (no retention needed)?
â”‚  â”œâ”€ YES â†’ Use TRUNCATE (fast but removes everything)
â”‚  â””â”€ NO â†’ Continue (need selective cleanup)
â”‚
â”œâ”€ Can table be offline briefly (<1 min)?
â”‚  â”œâ”€ YES â†’ Use Copy-to-New-Table (good for defrag)
â”‚  â””â”€ NO â†’ Use Batch DELETE (last resort, remember OPTIMIZE)
```

## Quick Start

### 1. Setup

Ensure the database environment is running:
```bash
cd ../task01
docker-compose up -d
```

### 2. Load Test Data

```bash
cd ../task03

# Load 10,000 rows (distributed over 20 days, ~50% older than 10 days)
./run-in-container.sh db-load.sh --rows 10000

# Load with verbose output
./run-in-container.sh db-load.sh --rows 20000 --verbose
```

### 3. Run Cleanup Methods

**Individual Methods**:
```bash
# Partition drop (default: 10 days retention)
./run-in-container.sh db-cleanup.sh --method partition_drop

# Truncate (removes ALL data)
./run-in-container.sh db-cleanup.sh --method truncate

# Copy with custom retention
./run-in-container.sh db-cleanup.sh --method copy --retention-days 7

# Batch delete with custom batch size
./run-in-container.sh db-cleanup.sh --method batch_delete --batch-size 10000
```

**All Methods for Comparison**:
```bash
./run-in-container.sh db-cleanup.sh --method all
```

### 4. Test with Concurrent Load

Simulate ongoing database activity:
```bash
# Terminal 1: Start background traffic
./run-in-container.sh db-traffic.sh --rows-per-second 20 &
TRAFFIC_PID=$!

# Terminal 2: Run cleanup
./run-in-container.sh db-cleanup.sh --method batch_delete

# Stop traffic
kill $TRAFFIC_PID
```

### 5. View Results

```bash
# List all results
ls -lh results/

# View a metrics log
cat results/partition_drop_*_metrics.log

# View batch DELETE per-batch metrics
cat results/batch_delete_*_batches.csv
```

## Command-Line Options

```bash
Usage: db-cleanup.sh [options]

Options:
  --method METHOD          Cleanup method: partition_drop, truncate, copy, batch_delete, all
  --table TABLE            Target table name (optional, uses default per method)
  --retention-days N       Days of data to retain (default: 10)
  --batch-size N           Batch size for DELETE method (default: 5000)
  --batch-delay N          Seconds between batches (default: 0.1)
  --test-metrics           Run metrics collection test
  --verbose                Enable detailed logging
  -h, --help               Show help message
```

## Metrics Collected

Each cleanup execution generates a comprehensive metrics log:

### Primary Metrics
- **rows_deleted_per_second**: Throughput (higher is better)
- **Duration**: Total cleanup time
- **Rows Deleted**: Exact count of removed rows

### InnoDB Metrics
- Innodb_rows_deleted (cumulative counter)
- Innodb_row_lock_time (lock wait time)
- Innodb_row_lock_waits (lock contentions)
- History list length (purge lag indicator)

### Table Size Metrics
- DATA_LENGTH, INDEX_LENGTH, DATA_FREE
- Space freed to OS
- Fragmentation percentage

### Replication Metrics
- Replication lag on replica (if available)
- Replication status

### Binlog Metrics
- Binlog growth in bytes

### Batch DELETE Specific
- Per-batch throughput
- Throughput degradation trend
- Max replication lag across batches

## Database Schema

### Tables

Four test tables with identical structure:

| Table               | Purpose                       | Special Features |
| ------------------- | ----------------------------- | ---------------- |
| cleanup_partitioned | Test DROP PARTITION method    | Daily partitions |
| cleanup_truncate    | Test TRUNCATE TABLE method    | Standard InnoDB  |
| cleanup_copy        | Test Copy-to-New-Table method | Standard InnoDB  |
| cleanup_batch       | Test Batch DELETE method      | Standard InnoDB  |

### Table Structure

```sql
CREATE TABLE cleanup_* (
  id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
  ts DATETIME NOT NULL,
  name CHAR(10) NOT NULL,
  data INT UNSIGNED NOT NULL,
  INDEX idx_ts_name (ts, name)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
```

### Partitioning (cleanup_partitioned only)

- **Type**: RANGE partitioning by `TO_DAYS(ts)`
- **Partitions**: Daily partitions (61 partitions initially)
- **Range**: 2025-10-21 to 2025-12-20
- **Overflow**: pFUTURE partition for future dates

## Supporting Scripts

### db-load.sh - Data Loading

Generates synthetic test data and loads all tables.

**Features**:
- Configurable row count
- Random timestamps spanning 20 days
- ~50% of data older than 10 days
- Reusable CSV for consistent datasets

**Usage**:
```bash
./run-in-container.sh db-load.sh --rows 100000
./run-in-container.sh db-load.sh --rows 50000 --verbose
./run-in-container.sh db-load.sh --rows 10000 --force-regenerate
```

### db-traffic.sh - Load Simulation

Simulates ongoing database activity during cleanup tests.

**Features**:
- Continuous INSERT, SELECT, UPDATE operations
- Configurable workload mix (default: 70:20:10)
- Adjustable operations per second
- Statistics reporting

**Usage**:
```bash
# Default: 10 ops/sec, all tables
./run-in-container.sh db-traffic.sh

# High write load
./run-in-container.sh db-traffic.sh --rows-per-second 20 --workload-mix 90:10:0

# Specific tables, 5 minutes
./run-in-container.sh db-traffic.sh --tables cleanup_batch,cleanup_copy --duration 300
```

### db-partition-maintenance.sh - Partition Management

Automates partition maintenance for cleanup_partitioned table.

**Features**:
- Adds new partitions for tomorrow
- Drops partitions older than retention window (30 days)
- Dry-run mode for testing

**Usage**:
```bash
# Preview actions
./run-in-container.sh db-partition-maintenance.sh --dry-run

# Execute maintenance
./run-in-container.sh db-partition-maintenance.sh

# Recommended: Schedule via cron (daily)
0 1 * * * /path/to/run-in-container.sh db-partition-maintenance.sh
```

## Results Directory

All metrics logs and batch data are saved to `task03/results/`:

```
results/
â”œâ”€â”€ partition_drop_YYYYMMDD_HHMMSS_metrics.log
â”œâ”€â”€ truncate_YYYYMMDD_HHMMSS_metrics.log
â”œâ”€â”€ copy_YYYYMMDD_HHMMSS_metrics.log
â”œâ”€â”€ batch_delete_NNNN_YYYYMMDD_HHMMSS_metrics.log
â””â”€â”€ batch_delete_NNNN_YYYYMMDD_HHMMSS_batches.csv
```

## Best Practices

### For Production Use

1. **Use DROP PARTITION** if your table is partitioned by date
   - Fastest and most efficient
   - No impact on application
   - No fragmentation

2. **Avoid TRUNCATE** for production tables with retention requirements
   - Only use for temporary/staging tables
   - Does not meet selective cleanup requirement

3. **Use Copy method** for scheduled maintenance
   - Run during low-traffic periods
   - Ensure sufficient disk space (2x table size)
   - Consider read-only mode during operation

4. **Use Batch DELETE** as last resort
   - When table must stay online 24/7
   - Tune batch size based on workload
   - Schedule OPTIMIZE TABLE during maintenance window

### Tuning Batch DELETE

**Batch Size Selection**:
- Small (1K): Lower impact, slower overall, better for high-traffic tables
- Medium (5K): Balanced approach (default)
- Large (10K+): Higher impact, faster overall, use during low-traffic

**Batch Delay**:
- Increase delay (0.5-1.0s) to reduce replication lag
- Decrease delay (0.05-0.1s) for faster cleanup

**Monitor**:
- Replication lag on replicas
- Query latency during cleanup
- Lock waits and contentions

## Troubleshooting

### No partitions to drop

**Cause**: Partitions already dropped or don't exist for retention window

**Solution**: 
- Check partition list: `SHOW CREATE TABLE cleanup_partitioned`
- Adjust retention days or load older data
- Recreate partitions with `db-partition-maintenance.sh`

### Batch DELETE finds no rows

**Cause**: Data already deleted or retention window is wrong

**Solution**:
- Check data distribution: `SELECT COUNT(*) FROM table WHERE ts < NOW() - INTERVAL 10 DAY`
- Reload data with `db-load.sh`
- Verify retention-days parameter

### High fragmentation after Batch DELETE

**Expected**: Batch DELETE does NOT free space

**Solution**:
```sql
OPTIMIZE TABLE cleanup_bench.cleanup_batch;
```

### Copy method loses data

**Expected behavior**: Data written during copy operation is lost

**Solution**:
- Run during maintenance window
- Use read-only mode
- Or use DROP PARTITION/Batch DELETE instead

## Troubleshooting

For detailed troubleshooting, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md).

### Quick Fixes

**Database not accessible**:
```bash
cd ../task01
docker-compose up -d
```

**Schema not loaded**:
```bash
./run-in-container.sh bash -c "mysql < /task03/db-schema.sql"
```

**No data to cleanup**:
```bash
./run-in-container.sh db-load.sh --rows 10000
```

**High fragmentation after batch delete**:
```bash
./run-in-container.sh bash -c "mysql -e 'OPTIMIZE TABLE cleanup_bench.cleanup_batch;'"
```

For more issues and solutions, see the complete [Troubleshooting Guide](TROUBLESHOOTING.md).

---

## Documentation

### User Guides

- **[README.md](README.md)** (this file) - Overview and quick start
- **[USAGE_GUIDE.md](USAGE_GUIDE.md)** - Detailed usage instructions and examples
- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - Common issues and solutions
- **[PRODUCTION_GUIDE.md](PRODUCTION_GUIDE.md)** - Production deployment guide
- **[RESULTS_INTERPRETATION.md](RESULTS_INTERPRETATION.md)** - How to analyze results

### Technical Documentation

- **memory-bank/** - Complete implementation documentation
  - `README.md` - Documentation index
  - `implementation.md` - Overall implementation index
  - `phase*_implementation_summary.md` - Phase summaries
  - `REQUIREMENT_COMPLIANCE.md` - Requirements compliance

### Getting Started

New to this project? Read in this order:
1. This README (overview and quick start)
2. [USAGE_GUIDE.md](USAGE_GUIDE.md) (how to use)
3. [RESULTS_INTERPRETATION.md](RESULTS_INTERPRETATION.md) (understand results)

---

## Project Structure

```
task03/
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ USAGE_GUIDE.md                   # Detailed usage guide
â”œâ”€â”€ TROUBLESHOOTING.md               # Troubleshooting guide
â”œâ”€â”€ PRODUCTION_GUIDE.md              # Production deployment
â”œâ”€â”€ RESULTS_INTERPRETATION.md        # Results analysis guide
â”œâ”€â”€ db-cleanup.sh                    # Main cleanup script (Phase 5)
â”œâ”€â”€ db-load.sh                       # Data loading script (Phase 2)
â”œâ”€â”€ db-traffic.sh                    # Load simulation script (Phase 3)
â”œâ”€â”€ db-partition-maintenance.sh      # Partition maintenance (Phase 1)
â”œâ”€â”€ db-schema.sql                    # Database schema (Phase 1)
â”œâ”€â”€ test-cleanup-methods.sh          # Test orchestration (Phase 6)
â”œâ”€â”€ run-in-container.sh              # Container execution wrapper
â”œâ”€â”€ results/                         # Metrics logs directory
â”œâ”€â”€ lib/                             # Test utilities (Phase 6)
â”‚   â”œâ”€â”€ test-utils.sh
â”‚   â””â”€â”€ test-scenarios.sh
â”œâ”€â”€ data/                            # Seed datasets (Phase 6)
â”‚   â”œâ”€â”€ events_seed_10k_v1.0.csv
â”‚   â””â”€â”€ events_seed_100k_v1.0.csv
â””â”€â”€ memory-bank/                     # Implementation documentation
    â”œâ”€â”€ README.md                    # Documentation index
    â”œâ”€â”€ implementation.md            # Overall implementation index
    â”œâ”€â”€ phase1_implementation_summary.md
    â”œâ”€â”€ phase2_implementation_summary.md
    â”œâ”€â”€ phase3_implementation_summary.md
    â”œâ”€â”€ phase4_implementation_summary.md
    â”œâ”€â”€ phase5_implementation_summary.md
    â”œâ”€â”€ phase6_implementation_summary.md
    â”œâ”€â”€ phase7_implementation_summary.md
    â””â”€â”€ ...
```

## Implementation Phases

- âœ… **Phase 1**: Database schema and partition maintenance
- âœ… **Phase 2**: Data loading script
- âœ… **Phase 3**: Load simulation script
- âœ… **Phase 4**: Metrics collection framework
- âœ… **Phase 5**: Cleanup methods implementation
- âœ… **Phase 6**: Testing and validation
- âœ… **Phase 7**: Final documentation

**ğŸ‰ PROJECT COMPLETE - ALL PHASES DONE ğŸ‰**

**Total Implementation**:
- ~7,100+ lines of code and documentation
- 4 cleanup methods fully implemented and tested
- Comprehensive testing framework
- Production-ready documentation

## Project Status

âœ… **COMPLETE** - All 7 phases finished (November 21, 2025)  
âœ… **PRODUCTION READY** - Full documentation, testing, and deployment guides  
âœ… **TESTED** - Comprehensive test framework with seed datasets  
âœ… **DOCUMENTED** - 2,400+ lines of user documentation

## License

Part of Porta One Bootcamp project.

## Related Documentation

- `memory-bank/phase5_implementation_summary.md` - Phase 5 implementation details
- `memory-bank/implementation.md` - Overall implementation index
- `memory-bank/REQUIREMENT_COMPLIANCE.md` - Requirements checklist
